{"name":"SLNSpeech","tagline":"Dataset proposed in IEEE TRANSACTIONS ON IMAGE PROCESSING \"SLNSpeech: solving extended speech separation problem by the help of sign language\"","body":"### Welcome to SLNSpeech Homepage.\r\nSLNSpeech contains three modalities: audio, visual, and sign language, and each modality corresponds to each other in time sequence. To the best of the authorsâ€™ knowledge, SLNSpeech dataset is the first dataset that coexists three modalities of audio, visual, and sign language, and can be used to explore the characteristics of these three modalities by using self-supervised learning methods.\r\n\r\n### Download\r\nPlease clone our [repository](https://github.com/cheerTT/SLNSpeech) for conducting detailed procedures. We suggest reading [README](http://cheertt.top/SLNSpeech/) before using the dataset. We also provide the processed dataset which can be found in [README](http://cheertt.top/SLNSpeech/). If you do not want to extend the dataset, you just download it.\r\n\r\n### License\r\nAll the SLNSpeech data is intended for academic and computational use only. No commercial usage is allowed. We highly respect copyright and privacy. If you find SLNSpeech violates your rights, please contact us.\r\n\r\nLicensed under the Computational Use of Data Agreement (C-UDA). Plaese refer to C-UDA-1.0.pdf for more information.\r\n\r\n### Citation\r\nPlease cite the SLNSpeech paper if it helps your research:\r\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\r\n\r\n### Contacts\r\n- [Taotao Li](http://cheertt.top/SLNSpeech/): 220184652@seu.edu.cn\r\n- [Jisong Wu](https://cse.seu.edu.cn/2019/0105/c23024a257549/page.htm): jswu@seu.edu.cn\r\n","note":"Don't delete this file! It's used internally to help with page regeneration."}